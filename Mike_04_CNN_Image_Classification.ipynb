{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c_ULc6ZOw7ge"
   },
   "source": [
    "<!--<img src=\"\" alt=\"drawing\" style=\"width:400px;\"/> -->\n",
    "<h1 style=\"text-align: center;\"><a title=\"Data Science-AIMS-Cmr-2021-22\">Convolutional Neural Networks for Image classification </h1>\n",
    "<!--<img src=\"\" alt=\"drawing\" style=\"width:400px;\"/> -->\n",
    "\n",
    "## Instructors:\n",
    "\n",
    "* Dr Bubacarr Bah\n",
    "\n",
    "* Rockefeller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zs3Vxo5dmP7j"
   },
   "source": [
    "\n",
    "\n",
    "***NOTE***\n",
    "\n",
    "<font color=\"red\">**Be sure to use hardware acceleration to use the GPU. Click on `Runtime`, change `runtime type`, and select `GPU` for the *hardware accelerator* option. Try to limit your time with the GPU. Terminate the session when possible due to limitations.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W--Tn2TNfUQc"
   },
   "source": [
    "## <font color=\"green\"> Learning outcomes:\n",
    "\n",
    "* learn how implement CNNs\n",
    "\n",
    "* learn about ```Conv2D, MaxPool2D, Flatten, Dropout```\n",
    "\n",
    "* learn how to implement ```ModelCheckpoint``` and view them in the file system\n",
    "\n",
    "* learn how to convert softmax output into class predictions\n",
    "\n",
    "## <font color=\"green\">Data information:\n",
    "\n",
    "* Features: (28x28) images\n",
    "\n",
    "* Output: 10 classes represented by integers\n",
    "\n",
    "## <font color=\"green\">Tasks for participants (boolean)?\n",
    "\n",
    "* Yes, at the end (try avoid copy/pasting code, rather write it out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpvo-bqTmP7m"
   },
   "source": [
    "## Imports first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nvCXvXq5mP7p"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X1GTR35cmP7v"
   },
   "source": [
    "## Load the dataset\n",
    "\n",
    "We will use the FashionMNIST dataset. Documentation https://www.tensorflow.org/datasets/catalog/fashion_mnist\n",
    "\n",
    "By the way, there are a ton of datasets already available to you from Tensorflow, check them out here: https://www.tensorflow.org/datasets/catalog/overview\n",
    "\n",
    "Fashion-MNIST is a dataset of Zalando's article images consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes.\n",
    "\n",
    "Note that the data has already been split into training and testing for us, phew! What's next though?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uQ_KjFJomP7x",
    "outputId": "a7f8fca7-9121-402f-dde2-1beaa4763a68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "29515/29515 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26421880/26421880 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "5148/5148 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4422102/4422102 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "(X_train, Y_train), (X_test, Y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-Lw_bPQKQFX"
   },
   "source": [
    "## View the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ueyWl-aUmP72",
    "outputId": "7b0548d9-77b6-4492-a8ce-8cef3d690a4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (60000, 28, 28) (60000,)\n"
     ]
    }
   ],
   "source": [
    "print('Training data shape : ', X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3bsoluyzBOYR",
    "outputId": "623f69d3-d875-4774-d475-200d10305ed1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data shape :  (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print('Testing data shape : ', X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z51sdOntmP78"
   },
   "source": [
    "## Find the unique numbers from the train labels\n",
    "\n",
    "From what we see below, we don't need to worry about label encoding as all the classes are integer values from 0 to 9 with no gaps between the values. Given that we have 10 classes, what does this tell us about the last layer in our network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o29O_gUTmP79",
    "outputId": "dc551bfe-ac4d-4f0d-c91a-396f569d54d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of outputs :  10\n",
      "Output classes :  [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "classes = np.unique(Y_train)\n",
    "nClasses = len(classes)\n",
    "print('Total number of outputs : ', nClasses)\n",
    "print('Output classes : ', classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMMjLgbimP8B"
   },
   "source": [
    "## Plot some of the data\n",
    "\n",
    "You can change the value of ```data_point``` to explore different images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "qQpW4rajmP8C",
    "outputId": "3835e101-d8ad-491c-8f27-7348499aa98e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Ground Truth : 1')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_point = 15\n",
    "\n",
    "plt.figure(figsize=[10,5])\n",
    "\n",
    "# Display the first image in training data\n",
    "plt.subplot(121)\n",
    "plt.imshow(X_train[data_point,:,:], cmap='gray')\n",
    "plt.title(\"Ground Truth : {}\".format(Y_train[data_point]))\n",
    "\n",
    "# Display the first image in testing data\n",
    "plt.subplot(122)\n",
    "plt.imshow(X_test[data_point,:,:], cmap='gray')\n",
    "plt.title(\"Ground Truth : {}\".format(Y_test[data_point]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BA_mGK_NVHwn"
   },
   "source": [
    "## Reshape needed\n",
    "\n",
    "Tensorflow wants to know the depth of an image. API https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D\n",
    "\n",
    "For CNNS, Tensorflow wants the format of the data as follows: [batches, rows, columns, depth].\n",
    "\n",
    "In this case the colour channel/depth of the images is 1. Currently the shape is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TBbn1qONB0M8",
    "outputId": "6482da42-719d-4752-c8e1-a9974a42ec81"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a55ZpEbCB6kQ"
   },
   "source": [
    "We have a width of 28 and a height of 28 but no depth. So we can reshape it to include a value of one using the Numpy reshape function. Documentation https://numpy.org/doc/stable/reference/generated/numpy.reshape.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D8HTp2YHVH4_"
   },
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2], 1))\n",
    "\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], X_test.shape[2], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-lQP7CElWVfe"
   },
   "source": [
    "## View the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5QKOvMPaWVfh",
    "outputId": "355ce66f-aff4-46d3-ea2f-582c711747b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (60000, 28, 28, 1) (60000,)\n"
     ]
    }
   ],
   "source": [
    "print('Training data shape : ', X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zzGxSUONCRb2",
    "outputId": "1c01e794-5351-454b-e8f4-89e9c3a53fe0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data shape :  (10000, 28, 28, 1) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print('Testing data shape : ', X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AyXyan4NCnVL"
   },
   "source": [
    "## Take a look at a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YNkeCMoUmP8Y",
    "outputId": "c0090971-56b5-4448-fe03-09428248bdf9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  1],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [ 13],\n",
       "        [ 73],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  1],\n",
       "        [  4],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  1],\n",
       "        [  1],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  3],\n",
       "        [  0],\n",
       "        [ 36],\n",
       "        [136],\n",
       "        [127],\n",
       "        [ 62],\n",
       "        [ 54],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  1],\n",
       "        [  3],\n",
       "        [  4],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  3]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  6],\n",
       "        [  0],\n",
       "        [102],\n",
       "        [204],\n",
       "        [176],\n",
       "        [134],\n",
       "        [144],\n",
       "        [123],\n",
       "        [ 23],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [ 12],\n",
       "        [ 10],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [155],\n",
       "        [236],\n",
       "        [207],\n",
       "        [178],\n",
       "        [107],\n",
       "        [156],\n",
       "        [161],\n",
       "        [109],\n",
       "        [ 64],\n",
       "        [ 23],\n",
       "        [ 77],\n",
       "        [130],\n",
       "        [ 72],\n",
       "        [ 15]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  1],\n",
       "        [  0],\n",
       "        [ 69],\n",
       "        [207],\n",
       "        [223],\n",
       "        [218],\n",
       "        [216],\n",
       "        [216],\n",
       "        [163],\n",
       "        [127],\n",
       "        [121],\n",
       "        [122],\n",
       "        [146],\n",
       "        [141],\n",
       "        [ 88],\n",
       "        [172],\n",
       "        [ 66]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  1],\n",
       "        [  1],\n",
       "        [  1],\n",
       "        [  0],\n",
       "        [200],\n",
       "        [232],\n",
       "        [232],\n",
       "        [233],\n",
       "        [229],\n",
       "        [223],\n",
       "        [223],\n",
       "        [215],\n",
       "        [213],\n",
       "        [164],\n",
       "        [127],\n",
       "        [123],\n",
       "        [196],\n",
       "        [229],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [183],\n",
       "        [225],\n",
       "        [216],\n",
       "        [223],\n",
       "        [228],\n",
       "        [235],\n",
       "        [227],\n",
       "        [224],\n",
       "        [222],\n",
       "        [224],\n",
       "        [221],\n",
       "        [223],\n",
       "        [245],\n",
       "        [173],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [193],\n",
       "        [228],\n",
       "        [218],\n",
       "        [213],\n",
       "        [198],\n",
       "        [180],\n",
       "        [212],\n",
       "        [210],\n",
       "        [211],\n",
       "        [213],\n",
       "        [223],\n",
       "        [220],\n",
       "        [243],\n",
       "        [202],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  1],\n",
       "        [  3],\n",
       "        [  0],\n",
       "        [ 12],\n",
       "        [219],\n",
       "        [220],\n",
       "        [212],\n",
       "        [218],\n",
       "        [192],\n",
       "        [169],\n",
       "        [227],\n",
       "        [208],\n",
       "        [218],\n",
       "        [224],\n",
       "        [212],\n",
       "        [226],\n",
       "        [197],\n",
       "        [209],\n",
       "        [ 52]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  6],\n",
       "        [  0],\n",
       "        [ 99],\n",
       "        [244],\n",
       "        [222],\n",
       "        [220],\n",
       "        [218],\n",
       "        [203],\n",
       "        [198],\n",
       "        [221],\n",
       "        [215],\n",
       "        [213],\n",
       "        [222],\n",
       "        [220],\n",
       "        [245],\n",
       "        [119],\n",
       "        [167],\n",
       "        [ 56]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  4],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [ 55],\n",
       "        [236],\n",
       "        [228],\n",
       "        [230],\n",
       "        [228],\n",
       "        [240],\n",
       "        [232],\n",
       "        [213],\n",
       "        [218],\n",
       "        [223],\n",
       "        [234],\n",
       "        [217],\n",
       "        [217],\n",
       "        [209],\n",
       "        [ 92],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  1],\n",
       "        [  4],\n",
       "        [  6],\n",
       "        [  7],\n",
       "        [  2],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [237],\n",
       "        [226],\n",
       "        [217],\n",
       "        [223],\n",
       "        [222],\n",
       "        [219],\n",
       "        [222],\n",
       "        [221],\n",
       "        [216],\n",
       "        [223],\n",
       "        [229],\n",
       "        [215],\n",
       "        [218],\n",
       "        [255],\n",
       "        [ 77],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  3],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [ 62],\n",
       "        [145],\n",
       "        [204],\n",
       "        [228],\n",
       "        [207],\n",
       "        [213],\n",
       "        [221],\n",
       "        [218],\n",
       "        [208],\n",
       "        [211],\n",
       "        [218],\n",
       "        [224],\n",
       "        [223],\n",
       "        [219],\n",
       "        [215],\n",
       "        [224],\n",
       "        [244],\n",
       "        [159],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [ 18],\n",
       "        [ 44],\n",
       "        [ 82],\n",
       "        [107],\n",
       "        [189],\n",
       "        [228],\n",
       "        [220],\n",
       "        [222],\n",
       "        [217],\n",
       "        [226],\n",
       "        [200],\n",
       "        [205],\n",
       "        [211],\n",
       "        [230],\n",
       "        [224],\n",
       "        [234],\n",
       "        [176],\n",
       "        [188],\n",
       "        [250],\n",
       "        [248],\n",
       "        [233],\n",
       "        [238],\n",
       "        [215],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [ 57],\n",
       "        [187],\n",
       "        [208],\n",
       "        [224],\n",
       "        [221],\n",
       "        [224],\n",
       "        [208],\n",
       "        [204],\n",
       "        [214],\n",
       "        [208],\n",
       "        [209],\n",
       "        [200],\n",
       "        [159],\n",
       "        [245],\n",
       "        [193],\n",
       "        [206],\n",
       "        [223],\n",
       "        [255],\n",
       "        [255],\n",
       "        [221],\n",
       "        [234],\n",
       "        [221],\n",
       "        [211],\n",
       "        [220],\n",
       "        [232],\n",
       "        [246],\n",
       "        [  0]],\n",
       "\n",
       "       [[  3],\n",
       "        [202],\n",
       "        [228],\n",
       "        [224],\n",
       "        [221],\n",
       "        [211],\n",
       "        [211],\n",
       "        [214],\n",
       "        [205],\n",
       "        [205],\n",
       "        [205],\n",
       "        [220],\n",
       "        [240],\n",
       "        [ 80],\n",
       "        [150],\n",
       "        [255],\n",
       "        [229],\n",
       "        [221],\n",
       "        [188],\n",
       "        [154],\n",
       "        [191],\n",
       "        [210],\n",
       "        [204],\n",
       "        [209],\n",
       "        [222],\n",
       "        [228],\n",
       "        [225],\n",
       "        [  0]],\n",
       "\n",
       "       [[ 98],\n",
       "        [233],\n",
       "        [198],\n",
       "        [210],\n",
       "        [222],\n",
       "        [229],\n",
       "        [229],\n",
       "        [234],\n",
       "        [249],\n",
       "        [220],\n",
       "        [194],\n",
       "        [215],\n",
       "        [217],\n",
       "        [241],\n",
       "        [ 65],\n",
       "        [ 73],\n",
       "        [106],\n",
       "        [117],\n",
       "        [168],\n",
       "        [219],\n",
       "        [221],\n",
       "        [215],\n",
       "        [217],\n",
       "        [223],\n",
       "        [223],\n",
       "        [224],\n",
       "        [229],\n",
       "        [ 29]],\n",
       "\n",
       "       [[ 75],\n",
       "        [204],\n",
       "        [212],\n",
       "        [204],\n",
       "        [193],\n",
       "        [205],\n",
       "        [211],\n",
       "        [225],\n",
       "        [216],\n",
       "        [185],\n",
       "        [197],\n",
       "        [206],\n",
       "        [198],\n",
       "        [213],\n",
       "        [240],\n",
       "        [195],\n",
       "        [227],\n",
       "        [245],\n",
       "        [239],\n",
       "        [223],\n",
       "        [218],\n",
       "        [212],\n",
       "        [209],\n",
       "        [222],\n",
       "        [220],\n",
       "        [221],\n",
       "        [230],\n",
       "        [ 67]],\n",
       "\n",
       "       [[ 48],\n",
       "        [203],\n",
       "        [183],\n",
       "        [194],\n",
       "        [213],\n",
       "        [197],\n",
       "        [185],\n",
       "        [190],\n",
       "        [194],\n",
       "        [192],\n",
       "        [202],\n",
       "        [214],\n",
       "        [219],\n",
       "        [221],\n",
       "        [220],\n",
       "        [236],\n",
       "        [225],\n",
       "        [216],\n",
       "        [199],\n",
       "        [206],\n",
       "        [186],\n",
       "        [181],\n",
       "        [177],\n",
       "        [172],\n",
       "        [181],\n",
       "        [205],\n",
       "        [206],\n",
       "        [115]],\n",
       "\n",
       "       [[  0],\n",
       "        [122],\n",
       "        [219],\n",
       "        [193],\n",
       "        [179],\n",
       "        [171],\n",
       "        [183],\n",
       "        [196],\n",
       "        [204],\n",
       "        [210],\n",
       "        [213],\n",
       "        [207],\n",
       "        [211],\n",
       "        [210],\n",
       "        [200],\n",
       "        [196],\n",
       "        [194],\n",
       "        [191],\n",
       "        [195],\n",
       "        [191],\n",
       "        [198],\n",
       "        [192],\n",
       "        [176],\n",
       "        [156],\n",
       "        [167],\n",
       "        [177],\n",
       "        [210],\n",
       "        [ 92]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [ 74],\n",
       "        [189],\n",
       "        [212],\n",
       "        [191],\n",
       "        [175],\n",
       "        [172],\n",
       "        [175],\n",
       "        [181],\n",
       "        [185],\n",
       "        [188],\n",
       "        [189],\n",
       "        [188],\n",
       "        [193],\n",
       "        [198],\n",
       "        [204],\n",
       "        [209],\n",
       "        [210],\n",
       "        [210],\n",
       "        [211],\n",
       "        [188],\n",
       "        [188],\n",
       "        [194],\n",
       "        [192],\n",
       "        [216],\n",
       "        [170],\n",
       "        [  0]],\n",
       "\n",
       "       [[  2],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [ 66],\n",
       "        [200],\n",
       "        [222],\n",
       "        [237],\n",
       "        [239],\n",
       "        [242],\n",
       "        [246],\n",
       "        [243],\n",
       "        [244],\n",
       "        [221],\n",
       "        [220],\n",
       "        [193],\n",
       "        [191],\n",
       "        [179],\n",
       "        [182],\n",
       "        [182],\n",
       "        [181],\n",
       "        [176],\n",
       "        [166],\n",
       "        [168],\n",
       "        [ 99],\n",
       "        [ 58],\n",
       "        [  0],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [ 40],\n",
       "        [ 61],\n",
       "        [ 44],\n",
       "        [ 72],\n",
       "        [ 41],\n",
       "        [ 35],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]],\n",
       "\n",
       "       [[  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0],\n",
       "        [  0]]], dtype=uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-fgq-DPpDY0y"
   },
   "source": [
    "## What is the min/max for this image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zk9fC6JDDUp3",
    "outputId": "08f2922a-1624-4a2a-cda2-74d2d8a4e177"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ciTWCBVjDXL3",
    "outputId": "668d9132-f1f7-4fd1-bb6e-5cf9ed70a797"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BykRwF2UmP8b"
   },
   "source": [
    "## Normalise\n",
    "\n",
    "We need to normalise the data since the values range from 0 to 255. Training NNs on data ranging between [0,1] is recommended.\n",
    "\n",
    "Need to normalise all features, including training, validation and testing. We also need to apply the same normalisation to any new data (obtained in the future)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FH2lcHF3mP8c"
   },
   "outputs": [],
   "source": [
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KXCZiTPZDB3d"
   },
   "source": [
    "## Take a look at a single image (after normalisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nRTTJ4kDDB_s",
    "outputId": "f42cd2bd-2a23-4dd4-c2b7-963796f9f408"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.05098039],\n",
       "        [0.28627451],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.01568627],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.00392157],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.01176471],\n",
       "        [0.        ],\n",
       "        [0.14117647],\n",
       "        [0.53333333],\n",
       "        [0.49803922],\n",
       "        [0.24313725],\n",
       "        [0.21176471],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.01176471],\n",
       "        [0.01568627],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.01176471]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.02352941],\n",
       "        [0.        ],\n",
       "        [0.4       ],\n",
       "        [0.8       ],\n",
       "        [0.69019608],\n",
       "        [0.5254902 ],\n",
       "        [0.56470588],\n",
       "        [0.48235294],\n",
       "        [0.09019608],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.04705882],\n",
       "        [0.03921569],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.60784314],\n",
       "        [0.9254902 ],\n",
       "        [0.81176471],\n",
       "        [0.69803922],\n",
       "        [0.41960784],\n",
       "        [0.61176471],\n",
       "        [0.63137255],\n",
       "        [0.42745098],\n",
       "        [0.25098039],\n",
       "        [0.09019608],\n",
       "        [0.30196078],\n",
       "        [0.50980392],\n",
       "        [0.28235294],\n",
       "        [0.05882353]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.        ],\n",
       "        [0.27058824],\n",
       "        [0.81176471],\n",
       "        [0.8745098 ],\n",
       "        [0.85490196],\n",
       "        [0.84705882],\n",
       "        [0.84705882],\n",
       "        [0.63921569],\n",
       "        [0.49803922],\n",
       "        [0.4745098 ],\n",
       "        [0.47843137],\n",
       "        [0.57254902],\n",
       "        [0.55294118],\n",
       "        [0.34509804],\n",
       "        [0.6745098 ],\n",
       "        [0.25882353]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.00392157],\n",
       "        [0.00392157],\n",
       "        [0.        ],\n",
       "        [0.78431373],\n",
       "        [0.90980392],\n",
       "        [0.90980392],\n",
       "        [0.91372549],\n",
       "        [0.89803922],\n",
       "        [0.8745098 ],\n",
       "        [0.8745098 ],\n",
       "        [0.84313725],\n",
       "        [0.83529412],\n",
       "        [0.64313725],\n",
       "        [0.49803922],\n",
       "        [0.48235294],\n",
       "        [0.76862745],\n",
       "        [0.89803922],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.71764706],\n",
       "        [0.88235294],\n",
       "        [0.84705882],\n",
       "        [0.8745098 ],\n",
       "        [0.89411765],\n",
       "        [0.92156863],\n",
       "        [0.89019608],\n",
       "        [0.87843137],\n",
       "        [0.87058824],\n",
       "        [0.87843137],\n",
       "        [0.86666667],\n",
       "        [0.8745098 ],\n",
       "        [0.96078431],\n",
       "        [0.67843137],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.75686275],\n",
       "        [0.89411765],\n",
       "        [0.85490196],\n",
       "        [0.83529412],\n",
       "        [0.77647059],\n",
       "        [0.70588235],\n",
       "        [0.83137255],\n",
       "        [0.82352941],\n",
       "        [0.82745098],\n",
       "        [0.83529412],\n",
       "        [0.8745098 ],\n",
       "        [0.8627451 ],\n",
       "        [0.95294118],\n",
       "        [0.79215686],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.01176471],\n",
       "        [0.        ],\n",
       "        [0.04705882],\n",
       "        [0.85882353],\n",
       "        [0.8627451 ],\n",
       "        [0.83137255],\n",
       "        [0.85490196],\n",
       "        [0.75294118],\n",
       "        [0.6627451 ],\n",
       "        [0.89019608],\n",
       "        [0.81568627],\n",
       "        [0.85490196],\n",
       "        [0.87843137],\n",
       "        [0.83137255],\n",
       "        [0.88627451],\n",
       "        [0.77254902],\n",
       "        [0.81960784],\n",
       "        [0.20392157]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.02352941],\n",
       "        [0.        ],\n",
       "        [0.38823529],\n",
       "        [0.95686275],\n",
       "        [0.87058824],\n",
       "        [0.8627451 ],\n",
       "        [0.85490196],\n",
       "        [0.79607843],\n",
       "        [0.77647059],\n",
       "        [0.86666667],\n",
       "        [0.84313725],\n",
       "        [0.83529412],\n",
       "        [0.87058824],\n",
       "        [0.8627451 ],\n",
       "        [0.96078431],\n",
       "        [0.46666667],\n",
       "        [0.65490196],\n",
       "        [0.21960784]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.01568627],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.21568627],\n",
       "        [0.9254902 ],\n",
       "        [0.89411765],\n",
       "        [0.90196078],\n",
       "        [0.89411765],\n",
       "        [0.94117647],\n",
       "        [0.90980392],\n",
       "        [0.83529412],\n",
       "        [0.85490196],\n",
       "        [0.8745098 ],\n",
       "        [0.91764706],\n",
       "        [0.85098039],\n",
       "        [0.85098039],\n",
       "        [0.81960784],\n",
       "        [0.36078431],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.01568627],\n",
       "        [0.02352941],\n",
       "        [0.02745098],\n",
       "        [0.00784314],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.92941176],\n",
       "        [0.88627451],\n",
       "        [0.85098039],\n",
       "        [0.8745098 ],\n",
       "        [0.87058824],\n",
       "        [0.85882353],\n",
       "        [0.87058824],\n",
       "        [0.86666667],\n",
       "        [0.84705882],\n",
       "        [0.8745098 ],\n",
       "        [0.89803922],\n",
       "        [0.84313725],\n",
       "        [0.85490196],\n",
       "        [1.        ],\n",
       "        [0.30196078],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.01176471],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.24313725],\n",
       "        [0.56862745],\n",
       "        [0.8       ],\n",
       "        [0.89411765],\n",
       "        [0.81176471],\n",
       "        [0.83529412],\n",
       "        [0.86666667],\n",
       "        [0.85490196],\n",
       "        [0.81568627],\n",
       "        [0.82745098],\n",
       "        [0.85490196],\n",
       "        [0.87843137],\n",
       "        [0.8745098 ],\n",
       "        [0.85882353],\n",
       "        [0.84313725],\n",
       "        [0.87843137],\n",
       "        [0.95686275],\n",
       "        [0.62352941],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.07058824],\n",
       "        [0.17254902],\n",
       "        [0.32156863],\n",
       "        [0.41960784],\n",
       "        [0.74117647],\n",
       "        [0.89411765],\n",
       "        [0.8627451 ],\n",
       "        [0.87058824],\n",
       "        [0.85098039],\n",
       "        [0.88627451],\n",
       "        [0.78431373],\n",
       "        [0.80392157],\n",
       "        [0.82745098],\n",
       "        [0.90196078],\n",
       "        [0.87843137],\n",
       "        [0.91764706],\n",
       "        [0.69019608],\n",
       "        [0.7372549 ],\n",
       "        [0.98039216],\n",
       "        [0.97254902],\n",
       "        [0.91372549],\n",
       "        [0.93333333],\n",
       "        [0.84313725],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.22352941],\n",
       "        [0.73333333],\n",
       "        [0.81568627],\n",
       "        [0.87843137],\n",
       "        [0.86666667],\n",
       "        [0.87843137],\n",
       "        [0.81568627],\n",
       "        [0.8       ],\n",
       "        [0.83921569],\n",
       "        [0.81568627],\n",
       "        [0.81960784],\n",
       "        [0.78431373],\n",
       "        [0.62352941],\n",
       "        [0.96078431],\n",
       "        [0.75686275],\n",
       "        [0.80784314],\n",
       "        [0.8745098 ],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [0.86666667],\n",
       "        [0.91764706],\n",
       "        [0.86666667],\n",
       "        [0.82745098],\n",
       "        [0.8627451 ],\n",
       "        [0.90980392],\n",
       "        [0.96470588],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.01176471],\n",
       "        [0.79215686],\n",
       "        [0.89411765],\n",
       "        [0.87843137],\n",
       "        [0.86666667],\n",
       "        [0.82745098],\n",
       "        [0.82745098],\n",
       "        [0.83921569],\n",
       "        [0.80392157],\n",
       "        [0.80392157],\n",
       "        [0.80392157],\n",
       "        [0.8627451 ],\n",
       "        [0.94117647],\n",
       "        [0.31372549],\n",
       "        [0.58823529],\n",
       "        [1.        ],\n",
       "        [0.89803922],\n",
       "        [0.86666667],\n",
       "        [0.7372549 ],\n",
       "        [0.60392157],\n",
       "        [0.74901961],\n",
       "        [0.82352941],\n",
       "        [0.8       ],\n",
       "        [0.81960784],\n",
       "        [0.87058824],\n",
       "        [0.89411765],\n",
       "        [0.88235294],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.38431373],\n",
       "        [0.91372549],\n",
       "        [0.77647059],\n",
       "        [0.82352941],\n",
       "        [0.87058824],\n",
       "        [0.89803922],\n",
       "        [0.89803922],\n",
       "        [0.91764706],\n",
       "        [0.97647059],\n",
       "        [0.8627451 ],\n",
       "        [0.76078431],\n",
       "        [0.84313725],\n",
       "        [0.85098039],\n",
       "        [0.94509804],\n",
       "        [0.25490196],\n",
       "        [0.28627451],\n",
       "        [0.41568627],\n",
       "        [0.45882353],\n",
       "        [0.65882353],\n",
       "        [0.85882353],\n",
       "        [0.86666667],\n",
       "        [0.84313725],\n",
       "        [0.85098039],\n",
       "        [0.8745098 ],\n",
       "        [0.8745098 ],\n",
       "        [0.87843137],\n",
       "        [0.89803922],\n",
       "        [0.11372549]],\n",
       "\n",
       "       [[0.29411765],\n",
       "        [0.8       ],\n",
       "        [0.83137255],\n",
       "        [0.8       ],\n",
       "        [0.75686275],\n",
       "        [0.80392157],\n",
       "        [0.82745098],\n",
       "        [0.88235294],\n",
       "        [0.84705882],\n",
       "        [0.7254902 ],\n",
       "        [0.77254902],\n",
       "        [0.80784314],\n",
       "        [0.77647059],\n",
       "        [0.83529412],\n",
       "        [0.94117647],\n",
       "        [0.76470588],\n",
       "        [0.89019608],\n",
       "        [0.96078431],\n",
       "        [0.9372549 ],\n",
       "        [0.8745098 ],\n",
       "        [0.85490196],\n",
       "        [0.83137255],\n",
       "        [0.81960784],\n",
       "        [0.87058824],\n",
       "        [0.8627451 ],\n",
       "        [0.86666667],\n",
       "        [0.90196078],\n",
       "        [0.2627451 ]],\n",
       "\n",
       "       [[0.18823529],\n",
       "        [0.79607843],\n",
       "        [0.71764706],\n",
       "        [0.76078431],\n",
       "        [0.83529412],\n",
       "        [0.77254902],\n",
       "        [0.7254902 ],\n",
       "        [0.74509804],\n",
       "        [0.76078431],\n",
       "        [0.75294118],\n",
       "        [0.79215686],\n",
       "        [0.83921569],\n",
       "        [0.85882353],\n",
       "        [0.86666667],\n",
       "        [0.8627451 ],\n",
       "        [0.9254902 ],\n",
       "        [0.88235294],\n",
       "        [0.84705882],\n",
       "        [0.78039216],\n",
       "        [0.80784314],\n",
       "        [0.72941176],\n",
       "        [0.70980392],\n",
       "        [0.69411765],\n",
       "        [0.6745098 ],\n",
       "        [0.70980392],\n",
       "        [0.80392157],\n",
       "        [0.80784314],\n",
       "        [0.45098039]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.47843137],\n",
       "        [0.85882353],\n",
       "        [0.75686275],\n",
       "        [0.70196078],\n",
       "        [0.67058824],\n",
       "        [0.71764706],\n",
       "        [0.76862745],\n",
       "        [0.8       ],\n",
       "        [0.82352941],\n",
       "        [0.83529412],\n",
       "        [0.81176471],\n",
       "        [0.82745098],\n",
       "        [0.82352941],\n",
       "        [0.78431373],\n",
       "        [0.76862745],\n",
       "        [0.76078431],\n",
       "        [0.74901961],\n",
       "        [0.76470588],\n",
       "        [0.74901961],\n",
       "        [0.77647059],\n",
       "        [0.75294118],\n",
       "        [0.69019608],\n",
       "        [0.61176471],\n",
       "        [0.65490196],\n",
       "        [0.69411765],\n",
       "        [0.82352941],\n",
       "        [0.36078431]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.29019608],\n",
       "        [0.74117647],\n",
       "        [0.83137255],\n",
       "        [0.74901961],\n",
       "        [0.68627451],\n",
       "        [0.6745098 ],\n",
       "        [0.68627451],\n",
       "        [0.70980392],\n",
       "        [0.7254902 ],\n",
       "        [0.7372549 ],\n",
       "        [0.74117647],\n",
       "        [0.7372549 ],\n",
       "        [0.75686275],\n",
       "        [0.77647059],\n",
       "        [0.8       ],\n",
       "        [0.81960784],\n",
       "        [0.82352941],\n",
       "        [0.82352941],\n",
       "        [0.82745098],\n",
       "        [0.7372549 ],\n",
       "        [0.7372549 ],\n",
       "        [0.76078431],\n",
       "        [0.75294118],\n",
       "        [0.84705882],\n",
       "        [0.66666667],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.00784314],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.25882353],\n",
       "        [0.78431373],\n",
       "        [0.87058824],\n",
       "        [0.92941176],\n",
       "        [0.9372549 ],\n",
       "        [0.94901961],\n",
       "        [0.96470588],\n",
       "        [0.95294118],\n",
       "        [0.95686275],\n",
       "        [0.86666667],\n",
       "        [0.8627451 ],\n",
       "        [0.75686275],\n",
       "        [0.74901961],\n",
       "        [0.70196078],\n",
       "        [0.71372549],\n",
       "        [0.71372549],\n",
       "        [0.70980392],\n",
       "        [0.69019608],\n",
       "        [0.65098039],\n",
       "        [0.65882353],\n",
       "        [0.38823529],\n",
       "        [0.22745098],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.15686275],\n",
       "        [0.23921569],\n",
       "        [0.17254902],\n",
       "        [0.28235294],\n",
       "        [0.16078431],\n",
       "        [0.1372549 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pzew90mNDdoJ"
   },
   "source": [
    "## What is the min/max for this image after normalisation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VzGZPbxvDdoO",
    "outputId": "23239743-088d-4799-cdaf-835f1876b47a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gGkND0LVDdoS",
    "outputId": "12bcc5ed-bb32-478d-f53b-1ca0da373085"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kj0QhPSsmP8e"
   },
   "source": [
    "## One hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sGRXrRTYmP8g"
   },
   "source": [
    "## Before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wrKyI7DamP8g",
    "outputId": "b347da72-1746-44de-b1ec-ff18993d1c29"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UfClFp-6K7P6"
   },
   "source": [
    "## Convert from categorical labels to one-hot encoded vectors\n",
    "\n",
    "In this case there are 10 classes so we can tell the function to convert into a vector of length 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i3xjsPnVmP8j"
   },
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(Y_train, 10)\n",
    "Y_test = np_utils.to_categorical(Y_test, 10)\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "92H9U6LkmP8m"
   },
   "source": [
    "## After"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tiiXZrnUmP8n",
    "outputId": "7bd97f20-5acc-441d-fddb-39bbc372169f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VungsdeHmP8u"
   },
   "source": [
    "## Create a CNN model\n",
    "\n",
    "A lot of things here are not new.\n",
    "\n",
    "Creating a sequential model is not new.\n",
    "\n",
    "Dropout is not new\n",
    "\n",
    "Creating a fully connected layer is not new.\n",
    "\n",
    "Creating a softmax output is not new.\n",
    "\n",
    "What's new is: Conv2D, MaxPooling2D and Flatten\n",
    "\n",
    "Documentation:\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0pJo4kNww7g2"
   },
   "source": [
    "## Building the CNN Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_4ZWKlXEw7g2"
   },
   "source": [
    "* On the first layer, we need to specify the `input shape`. Only here, only once. There below, we are creating 64 filters each of size 2x2. What will be the depth of each of those 64 filters? What will be the resulting depth of the feature map after applying these filters?\n",
    "\n",
    "\n",
    "*  \tone of \"valid\" or \"same\" (case-insensitive). \"valid\" means no padding. \"same\" results in padding with zeros evenly to the left/right or up/down of the input. When padding=\"same\" and strides=1, the output has the same size as the input.\n",
    "\n",
    "\n",
    "* Here we create a 2x2 max pooling layer\n",
    "\n",
    "\n",
    "* In order to pass output from the convolutional block to the dense block, we must flatten each example  in the minibatch. In other words, we take this four-dimensional input [batch, width, height, depth] and transform it  into the two-dimensional input [batch, units/input dimensions] expected by fully-connected layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m3a5q2wUw7g3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gozmsPxhmP8v"
   },
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1)))\n",
    "\n",
    "\n",
    "    model.add(MaxPool2D(pool_size=2))\n",
    "\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    optimizer = SGD(learning_rate=0.9)\n",
    "    loss = CategoricalCrossentropy()\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss=loss,\n",
    "             optimizer=optimizer,\n",
    "             metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q03EcUrxmP8x"
   },
   "outputs": [],
   "source": [
    "model = baseline_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bUN6K31smP80"
   },
   "source": [
    "## Determine the number of trainable parameters\n",
    "\n",
    "Look at how many parameters we get from the last layer in the feature extractor to the first fully connected layer in the classifier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_DxDanOHmP80",
    "outputId": "bda2d411-da96-45cd-f876-bd60a7efbfdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 64)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 12544)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                802880    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 805,610\n",
      "Trainable params: 805,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppxTtRIfBUgr"
   },
   "source": [
    "Now let's do something new. Let's save the model weights while training and keep track of the best model on the validation accuracy.\n",
    "\n",
    "API for saving checkpoints https://www.tensorflow.org/tutorials/keras/save_and_load and https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint\n",
    "\n",
    "Additional things like the ability to determine the latest checkpoint exists: `tf.train.latest_checkpoint`. Take a look at the documentation for more interesting things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HBQfomgaBUo3"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"training/cp-{epoch:04d}.ckpt\"\n",
    "\n",
    "cp_callback = ModelCheckpoint(filepath=checkpoint_path,\n",
    "                              save_best_only=True,\n",
    "                              save_weights_only=True,\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifPs0mftmP84"
   },
   "source": [
    "## Begin training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j8RZc1rhmP84",
    "outputId": "74643aff-25f3-4e73-f020-3467b1b435db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "235/235 [==============================] - ETA: 0s - loss: 1.3653 - accuracy: 0.4850\n",
      "Epoch 1: val_loss improved from inf to 0.73834, saving model to training/cp-0001.ckpt\n",
      "235/235 [==============================] - 10s 9ms/step - loss: 1.3653 - accuracy: 0.4850 - val_loss: 0.7383 - val_accuracy: 0.7180\n",
      "Epoch 2/10\n",
      "232/235 [============================>.] - ETA: 0s - loss: 0.7752 - accuracy: 0.7235\n",
      "Epoch 2: val_loss improved from 0.73834 to 0.59529, saving model to training/cp-0002.ckpt\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.7752 - accuracy: 0.7237 - val_loss: 0.5953 - val_accuracy: 0.7638\n",
      "Epoch 3/10\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.7344 - accuracy: 0.7426\n",
      "Epoch 3: val_loss improved from 0.59529 to 0.58474, saving model to training/cp-0003.ckpt\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.7344 - accuracy: 0.7426 - val_loss: 0.5847 - val_accuracy: 0.7999\n",
      "Epoch 4/10\n",
      "233/235 [============================>.] - ETA: 0s - loss: 0.7405 - accuracy: 0.7420\n",
      "Epoch 4: val_loss did not improve from 0.58474\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.7406 - accuracy: 0.7419 - val_loss: 0.6256 - val_accuracy: 0.7204\n",
      "Epoch 5/10\n",
      "233/235 [============================>.] - ETA: 0s - loss: 0.7265 - accuracy: 0.7483\n",
      "Epoch 5: val_loss improved from 0.58474 to 0.57572, saving model to training/cp-0005.ckpt\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.7264 - accuracy: 0.7483 - val_loss: 0.5757 - val_accuracy: 0.7927\n",
      "Epoch 6/10\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.7136 - accuracy: 0.7548\n",
      "Epoch 6: val_loss improved from 0.57572 to 0.50595, saving model to training/cp-0006.ckpt\n",
      "235/235 [==============================] - 2s 9ms/step - loss: 0.7136 - accuracy: 0.7548 - val_loss: 0.5059 - val_accuracy: 0.8190\n",
      "Epoch 7/10\n",
      "233/235 [============================>.] - ETA: 0s - loss: 0.7103 - accuracy: 0.7569\n",
      "Epoch 7: val_loss did not improve from 0.50595\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.7098 - accuracy: 0.7571 - val_loss: 0.5515 - val_accuracy: 0.8068\n",
      "Epoch 8/10\n",
      "228/235 [============================>.] - ETA: 0s - loss: 0.7023 - accuracy: 0.7600\n",
      "Epoch 8: val_loss did not improve from 0.50595\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.7026 - accuracy: 0.7600 - val_loss: 0.6246 - val_accuracy: 0.7634\n",
      "Epoch 9/10\n",
      "228/235 [============================>.] - ETA: 0s - loss: 0.6816 - accuracy: 0.7676\n",
      "Epoch 9: val_loss improved from 0.50595 to 0.50507, saving model to training/cp-0009.ckpt\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.6828 - accuracy: 0.7676 - val_loss: 0.5051 - val_accuracy: 0.8229\n",
      "Epoch 10/10\n",
      "229/235 [============================>.] - ETA: 0s - loss: 0.6779 - accuracy: 0.7694\n",
      "Epoch 10: val_loss improved from 0.50507 to 0.50213, saving model to training/cp-0010.ckpt\n",
      "235/235 [==============================] - 2s 8ms/step - loss: 0.6763 - accuracy: 0.7701 - val_loss: 0.5021 - val_accuracy: 0.8221\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd680212910>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=10, batch_size=256, verbose=1, callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2KRrCPwmCtkP"
   },
   "source": [
    "Check on the left using the `file` option. You'll see a new folder and the checkpoints saved. Next let's get the correct testing values and then compare the predictions on the test data when initialising the model as opposed to loading the best weights from training and predicting again on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "taRru5jrHm8P"
   },
   "outputs": [],
   "source": [
    "correct_values = np.argmax(Y_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Glts9LxlHeF_",
    "outputId": "a1a8c56b-771e-49e8-8589-65445f913a83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.79"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = baseline_model()\n",
    "predictions = model.predict(X_test)\n",
    "predictions = np.argmax(predictions, axis=-1)\n",
    "\n",
    "accuracy_score(predictions,correct_values)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQHPH-eIgRTM"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YrYa0jqFCtuO",
    "outputId": "dfe0833f-963b-4554-b43e-7e6aded6e07a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "82.21000000000001"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = baseline_model()\n",
    "model.load_weights(\"training/cp-0010.ckpt\")\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "predictions = np.argmax(predictions, axis=-1)\n",
    "\n",
    "accuracy_score(predictions,correct_values)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9do3Cl8vmP87"
   },
   "source": [
    "## Predict on one example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OnI4SnbEmP88",
    "outputId": "061fe7de-292d-4fb2-e7a0-f4614b9f848e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[8.2364816e-11, 4.1046036e-10, 2.0993464e-11, 3.3758491e-12,\n",
       "        1.3220822e-12, 4.5962529e-03, 1.7894112e-09, 7.1696527e-02,\n",
       "        6.7803521e-06, 9.2370039e-01]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.expand_dims(X_test[0], axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yW3HNzapEV47"
   },
   "source": [
    "## Predicting, but obtaining the probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "80LVXvFkEWEY",
    "outputId": "ad350e70-f07a-44af-9f7d-4d6744913f85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([9])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(np.expand_dims(X_test[0], axis=0))\n",
    "np.argmax(prediction, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_j9LecHgmP8_"
   },
   "source": [
    "## Predict on all the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7TtfkDWjmP8_",
    "outputId": "3e53d10a-4826-45a2-b4d4-8fc7e2bf258c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predictions = np.argmax(predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xBmZspLUmP9C",
    "outputId": "332511a2-dce3-4b59-ebb7-2dbb4dfdd9dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1, 1, 6, 1, 4, 6, 5, 7])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JKy0gGBhE2gX"
   },
   "source": [
    "Before applying the `accuracy_score` function we need to conver the data into single class integers. In it's current form, the Y_test values aren't suitable. To address this, we can use the `np.argmax` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PJiTOY3aWjcX",
    "outputId": "b3e4d3fb-46d0-47c4-c943-77226cdb29d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[839,   0,  20,  28,   7,   1, 288,   0,   3,   0],\n",
       "       [  1, 949,   0,  17,   3,   0,   1,   0,   1,   0],\n",
       "       [ 19,   0, 719,   7,  69,   0, 144,   0,   3,   1],\n",
       "       [ 84,  38,  23, 907,  64,   2,  54,   0,  16,   0],\n",
       "       [ 13,   6, 165,  17, 805,   0, 201,   0,   8,   1],\n",
       "       [  3,   0,   2,   1,   1, 898,   2,  15,   5,  19],\n",
       "       [ 32,   5,  66,  17,  41,   0, 285,   0,   9,   0],\n",
       "       [  1,   0,   1,   0,   0,  81,   1, 935,   4,  43],\n",
       "       [  8,   2,   4,   4,   9,   2,  23,   1, 949,   1],\n",
       "       [  0,   0,   0,   2,   1,  16,   1,  49,   2, 935]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(predictions,correct_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lEdkE4j--VzR"
   },
   "source": [
    "# Task:\n",
    "\n",
    "1) Add another convolutional layer to the current model.\n",
    "\n",
    "2) Add another max pooling layer to the current model.\n",
    "\n",
    "3) Modify the network and try improve your performance by using different architectures and hyper-parameters.\n",
    "\n",
    "4) Replace the max pooling with average pooling\n",
    "\n",
    "5) Add a stride of 2 to your average pooling layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FSKtAYriFQLO"
   },
   "source": [
    "# References:\n",
    "\n",
    "* This notebook was adpated from Dr. Emmanuel Dufourq,  2021 Gene Golub SIAM Summer School"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k69s9ScXw7g7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
